{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 64)          64000     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 164,106\n",
      "Trainable params: 164,106\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "# Add an Embedding layer expecting input vocab of size 1000, and\n",
    "# output embedding dimension of size 64.\n",
    "model.add(layers.Embedding(input_dim=1000, output_dim=64))\n",
    "\n",
    "# Add a LSTM layer with 128 internal units.\n",
    "model.add(layers.LSTM(128))\n",
    "\n",
    "# Add a Dense layer with 10 units.\n",
    "model.add(layers.Dense(10))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_16 (InputLayer)        [(None, 30, 3)]           0         \n",
      "_________________________________________________________________\n",
      "lstm_16 (LSTM)               [(None, 30, 64), (None, 6 17408     \n",
      "=================================================================\n",
      "Total params: 17,408\n",
      "Trainable params: 17,408\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# what is the unit parameter for class LSTM?\n",
    "# see https://zhuanlan.zhihu.com/p/58854907\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "Tx = 30\n",
    "n_x = 3\n",
    "n_s = 64\n",
    "X = Input(shape=(Tx, n_x))   \n",
    "s, a, c = LSTM(n_s, return_sequences=True, return_state=True)(X)    \n",
    "model_LSTM = Model(inputs=X, outputs=[s, a, c])\n",
    "model_LSTM.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_9 (LSTM)                (None, 30, 128)           67584     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 30, 10)            1290      \n",
      "=================================================================\n",
      "Total params: 68,874\n",
      "Trainable params: 68,874\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "Tx = 30\n",
    "n_x = 3\n",
    "n_s = 64\n",
    "\n",
    "model.add(Input(shape=(Tx, n_x)))\n",
    "\n",
    "# Add a LSTM layer with 128 internal units.\n",
    "model.add(layers.LSTM(128, return_sequences=True, return_state=False))\n",
    "\n",
    "# Add a Dense layer with 10 units.\n",
    "model.add(layers.Dense(10))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_25 (InputLayer)        [(None, 30, 3)]           0         \n",
      "_________________________________________________________________\n",
      "lstm_25 (LSTM)               (None, 30, 128)           67584     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 30, 10)            1290      \n",
      "=================================================================\n",
      "Total params: 68,874\n",
      "Trainable params: 68,874\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Tx = 30\n",
    "n_x = 3\n",
    "n_s = 64*2\n",
    "X = Input(shape=(Tx, n_x))   \n",
    "s = LSTM(n_s, return_sequences=True, return_state=False)(X)    \n",
    "d = Dense(10)(s)\n",
    "model_LSTM = Model(inputs=X, outputs=[d])\n",
    "model_LSTM.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: (32, 10, 8)\n",
      "output: (32, 4)\n",
      "whole_sequence_output: (32, 10, 4), final_memory_state: (32, 4), final_carry_state: (32, 4)\n"
     ]
    }
   ],
   "source": [
    "# Thema: return_sequences\n",
    "# from https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM\n",
    "\n",
    "# 32 = batch_size\n",
    "# 10 = 10 time steps\n",
    "# 8  = 8 features\n",
    "inputs = np.random.random([32, 10, 8]).astype(np.float32)\n",
    "print(f\"inputs: {inputs.shape}\")\n",
    "lstm = tf.keras.layers.LSTM(4)\n",
    "\n",
    "output = lstm(inputs)  # The output has shape `[32, 4]`.\n",
    "print(f\"output: {output.shape}\")\n",
    "\n",
    "lstm = tf.keras.layers.LSTM(4, return_sequences=True, return_state=True)\n",
    "\n",
    "# whole_sequence_output has shape `[32, 10, 4]`.\n",
    "# final_memory_state and final_carry_state both have shape `[32, 4]`.\n",
    "whole_sequence_output, final_memory_state, final_carry_state = lstm(inputs)\n",
    "print(f\"whole_sequence_output: {whole_sequence_output.shape}, final_memory_state: {final_memory_state.shape}, final_carry_state: {final_carry_state.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm cell: <keras.layers.recurrent.LSTM object at 0x000001F50BABA160>\n",
      "lstm1: Tensor(\"lstm_14_1/strided_slice_18:0\", shape=(None, 4), dtype=float32)\n",
      "output.shape: (1, 4)\n",
      "output = [[0.02765957 0.02765957 0.02765957 0.02765957]]\n"
     ]
    }
   ],
   "source": [
    "# Thema: return_sequences\n",
    "# https://www.dlology.com/blog/how-to-use-return_state-or-return_sequences-in-keras/\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import LSTM\n",
    "from numpy import array\n",
    "import keras\n",
    "\n",
    "k_init = keras.initializers.Constant(value=0.1)\n",
    "b_init = keras.initializers.Constant(value=0)\n",
    "r_init = keras.initializers.Constant(value=0.1)\n",
    "# LSTM units\n",
    "units = 4\n",
    "\n",
    "# define model\n",
    "inputs1 = Input(shape=(3, 2))\n",
    "\n",
    "lstm1 = LSTM(units, return_sequences=False, kernel_initializer=k_init, bias_initializer=b_init, recurrent_initializer=r_init)\n",
    "print(f\"lstm cell: {lstm1}\")\n",
    "lstm1 = lstm1(inputs1)\n",
    "print(f\"lstm1: {lstm1}\")\n",
    "model = Model(inputs=inputs1, outputs=lstm1)\n",
    "\n",
    "# define input data\n",
    "data = array([0.1, 0.2, 0.3, 0.1, 0.2, 0.3]).reshape((1,3,2))\n",
    "# make and show prediction\n",
    "output = model.predict(data)\n",
    "print(f\"output.shape: {output.shape}\\noutput = {output}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
